---
title: machinelearning cornerstone summary
copyright: true
top: 0
reward: false
mathjax: true
date: 2019-09-19 12:27:58
tags:
- machinelearning
- cornerstone
categories:
- [machinelearning, cornerstone]
---
what is ML?

1. 定义
人的过程，观察，学习到技能

机器的过程，数据学习到技能

技能即如何？

2. 关键
- 存在潜在的模式
- 没有很简单的定义
- 有足够的数据

3. 应用场景
衣食住行

4. 辨析
from f->ML->g: f为目标

ML vs DM： DM is interesting pattern, ML is find underlying pattern
ML vs AI: AI is 智能
ML vs Statistics: 统计是试图从以往数据中学习点什么出来

5. 例子
PLA， Perceptron算法，线性感知机法，主要想法是进行
eg： 图形结合的方法找最优解
> 假设： 1. 问题具有最优解  2. 样本真实，没有噪声

实际问题
- 算法怎么操作？
- 算法的正确性分析——算法能达到最优解。
    是否存在线性可分的直线，如果存在，那么研究是否收敛到最优解。然后算法是否能停止。
    > 收敛的分析，探究与最优解的接近程度，内积是一种方法
    > 是否停止，即到达常数。
- 算法的时空复杂度分析： 对算法进行比较

对于最优的算法，其返回结果必然是最优的。

> 每个算法的假设空间是否是一样的呢？
每一个问题都有假设空间，即其中参数来确定假设空间。但是由于假设空间不一定与问题空间对应，所以不一定能得到问题空间的解

> 这里是不是要看算法的类别？
对！

思考
如果假设1，2不成立怎么办？
假设没有噪声，但不知道是否可学习？
寻找经验误差最小的。
此时，经验误差最小的难度是NP-hard.
> 一种做法就是选择局部最优解来做。

线性w^T形成的就只是线吗？
> 对，只是线，这里其实是感知机模型，换句话说就只是所有样本点一起决定下的权值。
表示能力是否欠缺？
> 只有可以线性可分的数据集才可以用。

PLA算法更新公式确实是改变了一定的角度，如何保证该改变的角度一定就引起来类别的转化？

随机化算法是怎么做的？

扩展：
假设不知道算法是否存在最优解，采用口袋算法，即
算法流程：
    step1 随机选择一个w
    step2 如果有错误样本进行一次修正
    step3 没有错误则停止，否则重复执行step2
    
4. 分类
- 输出空间
    - 2
    - 多
    - 回归
    - 结构学习
- 资料
    - 监督
    - 非监督
    - 半监督
    - 强化
- 学习
    - Batch
    - online
    - active
- 特征
    - concrete具体
    - raw原始
    - abstrut 过于抽象，编号信息

5. 学习的前提
需要假设存在目标，且目标是一定的
Learning impossible, adversarial

于是在这里引入No Free Lunch, 目标不一定就无法进行学习，对！

学习的目标不可知, 如何学习？
还好有样本，可以使用概率论的概念即抽样来学习。

为什么可以学习？
利用的就是抽样。
- 对应关系：
问题空间->假设空间

- 关注样本，需要好的样本

> 不好的样例和不好的事