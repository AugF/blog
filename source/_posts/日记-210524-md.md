---
title: 日记-210524.md
copyright: true
top: 0
reward: false
mathjax: true
date: 2021-05-24 21:24:29
tags:
categories:
---

## 待思考的地方

P38:
结论应该怎么写？


## 讲稿

各位答辩老师下午好，我是王云攀，我的毕业论文题目是基于GPU的/图神经网络计算性能/优化研究，指导老师是黄宜华教授

我将从5个方面展开

首先来看研究背景/和相关工作

图神经网络是一种基于深度学习/处理图域数据/的方法，广泛应用于多个领域。
众多图神经网络系统，采样技术/和基于采样的训练推理流程被提出。

本文重点研究/面向GPU环境的图神经网络计算性能优化。

现有的性能评估工作对图神经网络训练推理过程计算效率方面的性能瓶颈研究不充分，如未涵盖训练阶段，且未考虑采样方法对性能瓶颈的影响

而目前的采样方法重点关注于优化采样方式，以降低采样对模型精度的影响，对算法流程上的计算效率缺乏关注

现有的分布式系统对GPU支持有限，单机多GPU系统也未关注到基于采样的训练推理流程中的内存开销问题。

本文的工作概述如下：

针对计算效率性能瓶颈不明确、缺乏相关分析工作的问题，研究设计了一系列实验，对基于GPU的图神经网络计算性能瓶颈做了系统性的分析。

性能分析发现，边计算是主要的性能瓶颈。高额的内存使用限制了图神经网络的数据扩展性。采样技术能有效降低内存使用，但基于采样的计算流程存在额外开销占比大导致GPU利用率低、内存波动大导致个别批次可能出现内存溢出两大问题。

针对训练推理流程GPU利用率低的问题，研究提出了基于流水线并行的训练推理流程优化方法。采样流程的流水线并行优化有效解决了采样流程额外开销大的问题。训练与评估步骤的流水线并行优化有效解决了评估步骤耗时长的问题。最终的实验结果证实了该优化方法的有效性。

针对不同批次内存开销波动大以及个别批次可能出现内存溢出风险的问题，研究提出了内存使用可控的训练推理流程优化方法。利用基于线性模型和随机森林的内存开销模型有效识别出可能带来内存风险的采样子图，并针对这些子图采取基于度数和PageRank的超限子图剪枝策略缩减子图规模，确保内存开销不超限。实验结果表明，两种预测模型有着非常高的精度，超限子图剪枝策略能有效限制子图的内存开销，且对模型精度的影响小于随机剪枝策略。

第二章将介绍性能瓶颈分析工作。

本文根据边/点复杂度将主流图神经网络算法划分在了四个象限，并选取了各个象限的代表算法GaAN, GGNN, GCN, GAT作为评估算法。

选取了七个性能评估中常用的数据集用于实验

以下是具体的实验设置，基于PyG实现了所有算法，并设计了统一的两层网络结构。

接着，我们从时间分解分析、内存使用分析，采样对性能的影响分析三个方面进行了性能瓶颈分析。

通过观察四个算法在图神经网络层的耗时分解，我们可以发现对于大多数情况，边计算占据了主要的耗时。

在PyG中，边计算被分解为了四个步骤，收集、消息传递、聚集和向量更新。

从边计算层耗时分解中可以分析，对于边计算复杂度高的算法（GAT和GaAN），消息传递是主要性能瓶颈。但边计算复杂度低时，收集和聚集步骤也占据了相当比例的耗时。

对于内存使用来说，定义内存膨胀比例为峰值内存与数据加载内存的壁纸，从图中可以看出，图神经网络计算过程存在着高额的内存开销。

基于采样的图神经网络训练推理流程以分批方式进行。单个批次包含了三个步骤：CPU端的采样，CPU端到GPU端的数据传输和GPU端的训练与推理。

通过比较不同批规模与全数据训练的内存使用，我们发现采样技术的确能显著减少内存使用！

在对单个批次训练耗时进行分解后，可以发现基于采样的训练推理存在的一个问题：采样和数据传输步骤占到了相当大的比例，该额外开销直接降低了GPU利用率。

通过内存使用分布箱线图可以发现基于采样的训练推理中的另一个问题：不同批次的内存开销波动很大，其中极个别批次可能导致内存溢出风险。

基于上述分析可以总结如下：
（1）边计算是大多数的图神经网络的性能瓶颈。
（2）高额内存使用限制了图神经网络的数据扩展性，采样技术能显著减少内存使用，将图神经网络扩展到大规模图数据集。但是，采样流程存在两大性能问题。第三章和第四章将分别解决这两大问题。

本部分的完整工作已在CCF-C类期刊上全文发表。

第三章将对基于流水线并行的训练推理流程优化方法进行介绍。

时间方面，对于图神经网络训练推理流程，除了采样流程的额外开销显著外，还存在着训练过程的评估步骤耗时较长的问题。本章将通过流水线的方式解决这两大性能问题。

如图所示，通过理论加速比的分析可以发现，理论加速比与总计算批次、采样、数据传输步骤的耗时占比关。

对于该优化具体实现，本文使用了基于CUDA流实现了采样和数据传输步骤的并发执行。基于数据预取技术，借助双线程和队列实现了采样数据传输步骤和GPU计算步骤的并发执行。

对于训练与评估步骤的流水线并行优化，同理，可以发现理论加速比与训练轮数和评估耗时占比相关。

对于具体实现，基于多进程和本地文件数据共享进行了实现。总共维护了三个进程，主进程负责总控制，训练进程负责模型训练，评估进程负责模型评估。训练进程和评估进程通过本地文件进行数据交换。

由于实际中采样、数据传输、评估耗时占比一直发生变化，实际加速比的代表意义不强。这里将优化效果定义为了实际加速比与理论加速比的比值。

其他设置与第二章保持一致。

从图中可以发现，优化效果只与总耗时相关，随总耗时增加而增加，其他因素通过影响总耗时影响优化效果。这是因为实现本身的额外开销一定，总耗时越多，意味着额外开销占比越少，从而优化效果更好。

在训练与评估步骤的优化效果评估中，同理观察到了类似的结论。

对于叠加优化效果评估，虽然具体的优化比值存在差异，在大多数情况下，优化1+优化2的组合可以取得更好的优化效果。

第四章将介绍内存使用可控的训练推理流程优化方法。

GPU内存有限，如何在有限的条件下安全地实现大规模的图神经网络训练推理变得至关重要。由第二章分析知，基于采样的训练推理流程能大幅降低计算过程中的内存开销。但该流程存在不同批次内存波动大从而个别批次触发内存溢出风险问题。

从内存安全角度，研究内存使用可控的图神经网络训练推理流程变得非常重要。

下图展示了总流程设计。

我们在单个批次的常规训练流程中加入了内存超限处理步骤，负责发现和处理超限采样子图。面对不同的应用场景，我们提出了两种不同的预测模型：线性模型和随机森林。由于推理阶段必须对采样子图推理，推理阶段直接进入剪枝处理机制。为了避免对模型精度的影响，对于训练阶段，会尝试一定次数的重采样，再执行剪枝处理机制。

确定超参数场景指算法的超参数、数据集规模和批规模等所有均确定的场景，常出现于图神经网络应用阶段或开发阶段的某个具体步骤。

基于峰值内存开销与输入图的二元线性关系，在此场景下，可直接基于边数和点数的二元线性模型预测内存开销。

非确定超参数场景指仅图神经网络结构确定（算法确定），其他均可以不确定的场景，常出现与图神经网络的设计阶段。基于多个参数对具体值建模，本质上为回归问题。

通过对多种已有的机器学习方法比较，随机森林综合表现最好，选择其作为了预测模型。

为了获得较为精确的模型，在训练或推理之前会构造一定数量的样本预训练模型。
为了进一步提高模型的精度，在训练或推理过程中，会基于确定阈值对模型进行在线更新。

基于对峰值内存与图的边数的线性关系，可以使用二分搜索作为采样子图规模上界预测方法。

对于采样子图剪枝处理总流程，在通过规模上界预测方法得到剪枝边数后，会基于边的重要性评估所有边并剪枝掉重要性低的边以缩减采样子图。这里设计了基于度数和PageRank信息设计了两种边重要性衡量方法，其基本思想是一条边的两个顶点越重要，那么其边越不重要。

预测模型的评价指标，误差方面选取了MAPE(平均绝对百分比误差)；准确率方面选取了R2决定系数指标。其他设置与第二章保持一致。

从线性模型的测试集上的分析结果可以发现，线性模型表现出来非常好的性能，误差小于0.006， 准确率均在99%以上。（）

如图展示了随机森林与其他机器学习方面对比，可以发现，随着训练集规模的增加，随机森林在两个指标上表现最好。

对于预测模型的额外开销，可以发现，额外开销很稳定，而且值也很小。

同时，我们展示了实际模拟情况下的预测效果，可以发现，两种模型所有批次的内存开销均成功控制在了指定GPU内存限制内。

如图展示了推理阶段使用采样子图规模上界预测方法和随机剪枝策略后的内存分布箱线图，可以看出，所有批次的内存开销均控制在了指定GPU内存限制内

首先，我们评估了不同剪枝比例下的各个算法的精度情况。可以发现，绝大多数情况下，两种剪枝的精度均优于随机剪枝。同时，使用剪枝可能取得更好的模型精度！

对实际情况来说，除了PageRank剪枝在ClusterGCN算法和ogbn-products数据集上的情况外，两种剪枝精度均优于随机剪枝。

由于本文提出了剪枝策略使用了多余的信息，所以两种剪枝策略耗时高于随机剪枝。但由于实际情况中剪枝策略发生的比例非常小（如表所示，实际情况中均小于14%），所以不会带来太多的额外开销！

本文工作总结如下：
第一，研究设计了一系列实验，对基于GPU的图神经网络计算性能进行了系统性的分析。选取了四个代表性算法，从时间、内存和采样对性能的影响三个方面进行了分析

第二，研究了提出了基于流水线并行的训练推理流程优化方法。实现了采样流程的流水线优化和训练与评估步骤的流水线优化，实验证实了该优化方法的有效性。

第三，研究提出了内存使用可控的训练推理流程优化方法。提出了基于线性模型和随机森林的内存开销预测模型；提出了基于二分搜素的采样子图规模上界预测方法和基于度数和PageRank的超限子图剪枝策略。实验证实了该优化方法的有效性。

未来工作考虑从三个方面展开：
1. 多GPU或分布式环境下的训练推理流程性能优化。
2. 面向具有动态拓扑结构的时空图数据集的性能优化
3. 新兴的图神经网络编程模型的性能差异

这是我在研究生期间的主要工作

最后，感谢各位老师和同学，以上就是我的硕士论文答辩

## TODO

1. 前面研究背景还存在很大的问题
> 这里需要添加的内容太多了

优先级：先完成必须要改的，然后再考虑怎么改

2. “研究背景与动机”应该怎么写？
> ?


## 安排

1. 先第一遍把自己觉得有问题的地方改正
2. 写一遍稿子，从而来检查自己的通顺程度
3. 调格式，调字体
> 1,2,3目标为将PPT完成好
> 不能出现不通顺，错别字等问题

4. 反复修改演讲稿
5. 背演讲稿（反复累计10遍）

6. 累计10遍以后
7. 计时排练（争取在10分钟左右），同时详略得当
8. 现场放映，并观看PPT的显示是否有问题，是否需要调整PPT的字体。

## 纠正自己的作息

认识自己，坚持做一件事！
