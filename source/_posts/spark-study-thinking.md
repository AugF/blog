---
title: spark study thinking
copyright: true
top: 0
reward: false
mathjax: true
date: 2019-09-19 13:06:59
tags:
- spark
- thinking
categories:
- [spark, thinking]
---

```

    val file_split = args(2).toInt  // 文件的切分，将文件划分为多少个mapper
    val numPartition = args(3).toInt // mapper后，形成多少个reducer

    // 还有其他建议参数
    // driver-memory, driver-cores 内存主要是启动内存，存储启动的数据，
    // ? driver所使用的数据，首先数据本身是可以放在多个位置吧，然后，其次，数据来源是本地文件的话，应该也可以在worker节点上，因为这样本身就可以做，在task执行时，直接就近选取接地那执行即可
    // 其而，是当执行collect()时， 数据将被拉回driver端？？？

    // executor-memory, executor-cores:

    // spark-default-parrallism: 如果一直从头默认，尽管是reduceByKey, 它有个参数partitioner也使用的是默认，那么这样看来也就是说基本上都是这个参数，除非中间设置repartitiones; 这里官方的建议是总cores的2-4倍

    // 然后 executor和worker,driver的对应, 首先系统会计算driver,worker剩下的内存，然后按照某种策略（一个worker装满再装下一个，还是一个一个worker地装）, 于是就形成了执行单元。

    // 对于每个executor, 在执行时必然需要用到数据，会采用就近原则，比如使用的是hdfs架构时，会优先从某个就近的地方读取

    // 分给每个executor的内存，有几个用途：1. 运行，包括代码执行, 所以有堆外内存，用于调节GC; 

    // executor:  executor-cores， 按系统能给的最大程度在每个worker上给予的方式来分配executor. 然后executor, 然后，关于executor启动以及后面的执行又是怎么折腾的呢？怎么看出负载均衡这些东西的？ spark-ui
    https://blog.csdn.net/dandykang/article/details/48525467
    
```

所以整个并行化，spark需要关注的点

1. mapper前的预处理操作
2. 数据传送到mapper的开销
3. mapper的个数
> task执行完后的负载均衡, 有小任务和大任务，有的先执行完，有的后执行完
4. mapper数据汇集的通信开销
> 这个过程又名shuffle,  shuffle read: 抓取数据, 这里涉及到将mapper的结果抓取过来，然后进一步考虑怎么搞;  shuffle write: 将数据按key值分发到各个reducer上
> 感觉上处理shuffle的是保存一个类似hash的东西来做的

5. reducer的个数
> reducer再将结果汇聚到driver端


关于一些默认的东西一般在spark安装的文件里，进行spark安装环境的解析

然后具体怎么做的，就主要的想法是参照源码


然后，涉及到整个系统的：

1. 环境准备，怎么将所有东西给放在一起

2. 代码执行
    - 集群初始化：面向对象的思想，首选一个外部消息导致整个事件触发，然后如此直到达到某个结束标志
        - 调度单位，将事情作为不同方面进行调度；比如，掌管通信的，掌管DAG的，然后，再起对应的名字；最终再进行来做
    - Dirver端执行代码，分配到mapper端，惰性求值，当在mapper端遇到需要收集数据，即需要将这个数据分离时，即认为该stage结束，则开始进行运算。 这里会进行DAG世袭图的计算。
    > DAG世袭图的提出
    > 查看sparkUI
    - 如何保证容错
    > 这里的想法就是在整个Driver端维持？，还是？。不对！应该是会维持计算图，首先进行思考，优先从就近的前一步抓取未计算完的数据。所以，这就意味着把某一步的RDD计算结果放在某一个位置上于是就显得很重要了！
    - 这里的checkpoint，已然忘记是不是说的也就是这个感觉

3. 数据库操作，SQL层抽象，存储，hdfs存储到每个节点

SparkUI的几个东西： 18080;  系统： 8080
- jobs
job的概念，其实也就是一次map/reduce过程，当然也可以看作是action操作结束后。唯一需要特别注意的是，job最终即action的结果又会回到Driver端，由系统再次分配job.  一个SparkContext中一个任务，一个任务多个job.
> 物理时，Master, Slaves
> 工作时，Driver, Worker   Dirver不等于Master，因为Dirver根据不同的执行方式，可以分布在不同的位置，比如 各种部署模式
> > 本地模型 local[4], 用来模拟线程; Client提交任务，所以我们很多时候一般都是上环境进行提交任务Driver; 在Standalone, 这里指的是master单独的意思，即spark defalut， 此时Master=Driver; 其余有两种，一种是本地为Dirver端，与集群进行交互，但是本地机器不是集群机器，当运行大量任务时，会带来很严重的开销';一种是本地把代码提交到集群，集群再选择一个节点做Driver，注意此时每个节点的地位相同
    - event timeline: executor的执行状态 <font color="red">可以分析出来是否负载均衡</font>
    - DAG visualization: 整个的stage图，就是按宽stage和窄stage来进行划分
    - Skipped Stages, Failed Stages
- stages
对于每个stages由着以下的指标：
    - 任务延迟
    - 持续时间
    - GC Time
    - Shuffle Red Blocked Time
    - Shuffle Read Size

    - 每个executor的状态数据
    - 每个tasks的执行状况
- storage
存储，关于在每个点或者其他点上存储的东西
- environment
    - runtime information
    - spark properties
    - classpath entries
- Executors: 每个executors的执行状态



整个Spark技术内幕主要包括以下几个方面：
- RDD的实现

- Scheduler模块
> 关于调度如何实现的

- Deplo模块
> 消息传递，容错，运行模式

- Executor模块
> 分配， task的执行

- Shuffle模块
> Hash Based Read/ Shuffle Write

- Storge
> 存储模块


Spark编程需要的内容
- scala常用数据类型的了解
- spark编程环境的问题
- RDD编程
> 创建RDD， RDD的各种操作，常见转化和行动操作， 持久化
- 键值对操作*
> 主要说的是PairRDD, 目前来说，并没遇到
- 数据读取和保存
> 本地和hdfs://master:9000  
- 进阶*
> 累加器，广播变量，基于分区操作，与外部程序间的管道，数值RDD的操作
- 运行spark-submit, 打包和依赖
- 关键性能度量
    - 并行度
    - 序列化格式： 这里好像只涉及到使用 kryo工具
    - 内存管理
    - 硬件供给
- Spark Sql* 
> 未涉及到，好像后面可以通过sql语句直接得到，所以超级简单

一些实战
> 进行数据分析，从而来提高熟练度

## 2. 语言编程

数据结构
1. 变量，常量
2. 物理上不同的类型
    - 基本类型，Int,String
    - 静态数据结构，长度不可变，比如List, Array, 
    - 变长 vector, ArrayBuffer; 
    - hash结构，
    - tree结构， 堆
    - 抽象结构，栈、队列
    - (key, value)对
    > 注意思考，一般这种的内部实现是什么样的; 比如说平衡二叉树
3. 访问特性来看
    - 迭代器，只支持iterator
    - travesac: 支持随机访问
    - 支持从前或者从后访问

3. 基本操作符：  +, -,  ==, equals, >=, ., ->
4. 扩展操作符： ++=  -- 

5. 常见操作
    - 合并两个集合
    - 插入某个元素，某个元素不存在
    - 删除某个元素，元素不存在
    - 查看某个元素是否存在
    - 判断是否为空
    - 初始化
    - 是否为满
    - 清空
    - 转换为其他集合
    > 默认hashCode, ==, euqals的实现, >小于比较的实现

6. 泛型
    - 支持所有类型
    > 迭代器
    - 抽象的算法

7. 类
    - 抽象类， 接口
    - 抽象抽象类， traits
    - 类的继承，派生； 可以互用的方法
    
8. 其他编程范式
    - map(),  reduce()等以及扩展的操作，还有变量在里面或者变量在外面

9. 基本常见语句的操作：循环，条件；特殊的语句

10. 其他类别：
    - 文件操作，交互
    - 异常处理，捕捉
    > try, catch;  assert();  宏语句来一件更改是否执行, 继承测试

11. 多文件
    - 整个项目，组；
        - 资源文件
        - 配置文件
        - 测试文件
        - 源代码
            - 包的概念， 包这里的概念与C中不同可以理解为物理上的文件组织转换为了包
            > 更进一步从文件上分割了各个包，使得文件的组织更加合理
                - 功能划分： 实体，数据库访问层，网页层，逻辑层
                > 按照功能，或者考虑用其他的方式进行划分
            - 类的概念
    - 引用已有代码： 这里是人类的精华，使用依赖的概念。
        - 如何进行管理这些依赖的东西？ jar(java), .net(C++类库)
        - 在自己的工程中引用: mvn管理， pom文件配置，自动化处理包
        > 将资源放在云端，maven， 需要地则通过网络拉取在编译时进行整合到程序中
    > 这里是在一般机器所有层上进行扩展的。
    > 比如如果是java, 首先机器上是具备有jvm虚拟机的。C++, MinGW, 所以之后的包的所有东西都是基于这些基本的接口进行调用的。所以是更上一层的抽象.

    - 因为涉及到各种功能，所以需要考虑计算机的基本功能进行支持，比如
        - 计算机网络：联网与其他计算机进行交互
        - 计算机文件系统： linux相关命令
        - 安全： 设置网络访问权限，网络防火墙，从小到大网络的权限的设置。从网络向下到各层文件，所以又涉及到各层文件的私密网络。 外加网络通信
        - 接口，与外部显示器，音箱，键盘等各种输入输出设备的兼容
    
    - 再向下，计算机上层功能的实现，全都可以抽象为一台具有CPU计算，存储和输入输出的机器。输入则认为是代码，输出则认为是结果。
    > 不管是图像显示还是声音，可以看作是输出在特定物理设备上的反映。它遵从一定的物理表现形式就可以表现为某个点。声音是频率，图像是光的变化，即像素点
    > 对于文件系统的功能，可以看作是有超大的一块内存，然后按某种特别地形式对文件进行组织管理，于是乎就可以抽象出各类文件。这块地方其实先划分为块，然后再划分为其他。也可以分为系统区，文件节点区，具体文件区，其他所有的不过是层抽象。
    > 对于安全，不过是对输入输出进行处理。计算机网络，对输入进行处理

    - 再向下，CPU可以抽象为一个累加器？，或者其他什么，这一层可以放在上层。根据图灵机知道这是可行的；然后，实际上可以由累加器来看出由0,1的基本的与，或，非，对应于各类的逻辑电路，最终然后得到各种功能的叠加

    - 最向下，于是就到了逻辑管层


    - 往上，编译原理，当一段抽象代码出来时机器是怎么做的呢，首先，将所有依赖的东西加进来然后构成源代码。接着，将源代码进行词法、语法分析，接着进行会形成一些底层一点的东西，进行符号表解析，最简单的理解就是把所有文件，都不歧义地翻译为一个文件的内容。当然，中间因为是对多文件进行翻译，所以需要一些基本的辅助数据结构，如符号表。因为从某种意义上来说，最终结果为汇编语言，而汇编语言并没有什么特别的语言结构，所以需要把变量和函数都给简单地组织为需要进行访问几次内存，等来做。 
    最终代码执行阶段，所谓代码执行，也就是将静态转换为动态，根据代码中初始化的东西进行分配资源，根据算法进行代码运行，然后最终出结果
    > 编译器一定都是有shell终端的，所以很多时候远远可以考虑使用shell终端来进行机器
12. 如果共享网络


new
1. 算法
    - 并行化算法
    - 串行化算
