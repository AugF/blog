---
title: neu ai course
copyright: true
top: 0
reward: false
mathjax: true
date: 2019-09-19 09:24:12
tags:
- ai
- neu
- course
categories:
- [course, neu, ai]
---
## 人工智能

### 1. 智能体与环境

智能体：通过传感器感知所处环境并通过执行器对该环境产生作用的计算机程序及其控制的硬件。

任务环境

智能体种类，性能度量，环境，执行器，传感器

> 智能体在环境中使用传感器，根据性能度量执行执行器。也就是智能体与环境的一个交互的过程。
>
> 任务环境：可观察与不可观察，确定性的与随机的，片段式的与延续式的
>
> 基于反射、模型、目标、效用的智能体



### 2. 知识表示

多种类别

- 一阶谓词

- 产生式

- 语义网络

- 框架

- 剧本

- 过程

- 面向对象

- Petri网

  库所和变迁，有向狐，以及令牌等元素组成。

- 信念网

- 本体论

#### 状态空间表示法

两种：

- 问题求解状态空间图
- 完整状态空间图

> 状态空间法表示法：
>
> - 初试状态集合S
> - 操作F：走步、产生式、规则、数学算子、运算符号或逻辑符号等 
> - 目标状态集合G:
>
> 作用：
>
> 提供 了一种新的解题思路，将问题重新表示。可以将实际问题的为无数的小块，将其隐含地转化为状态来做。然后，一种最简单的策略就是看与最终状态的相差值来看是否查看（一般还可以利用其它评价指标，这里突然想到了机器学习，是怎么想到各种评价指标的呢，从某种意义上还可以不停地多套）

方法：搜索

>八数码问题

- 不可撤回式

> 沿一条路径单向延伸搜索
>
> 局部知识的利用，比如W(n)最大为原则来选择规则; 但可能停留在局部最优值

- 可撤回

> 1. 回溯，可修正搜索路径
> 2. 图搜索，展开式搜索，可保留完整的搜索树

### 3. 搜索问题

> 状态空间： 由给定问题的所有可能状态组成的空间（全集G）
>
> 搜索空间：按某种策略在状态空间中选取的部分空间（G的子集）
>
> 解路径：求解问题的一条有效路径
>
> 搜索策略的基本思路：搜索空间中必有解路径；如果问题由解，尽量缩小搜索空间，且能否找到最佳解。
>
> 搜索策略的评价准则：总体费用最低，费用包括两部分：
>
> - 规则应用费用，执行规则的费用
> - 控制费用：选择规则的费用



> 3.1和3.2是无信息搜索策略，3.3是启发式搜索策略

#### 3.1 回溯策略

> 原问题要选取的点化为多个点，选取每个点即为规则。所以在这里最重要的就是规则的排列，就是如果排列选取规则。

#### 3.2 图搜索

```
算法看上去没有那么复杂：
要点1：
- OPEN: 尚未扩充的节点； CLOSED:已经扩充过的节点
- G中每个节点都唯一地指向一个父节点，意味着只能选取一个来做
- {mi} = {mj} U {mk} U {m1}， 当前被扩充的全部节点=新扩充节点+OPEN+CLOSED
- n是当前被选中的节点，它是OPEN表中排列在最前面的一个节点
- 该算法对于连通图及树都适用

> 跟DFS不同的是，在扩展完节点后，修改原本已经是黑色节点的最优值，即这些节点的父亲节点可能会进行改变。
```



> DFS和BFS
>
> BFS的变形：一致性搜索（每个点有评价指标，评价指标最重要），迭代加深搜索（限定深度，先DFS，再BFS）

#### 3.3 启发式图搜索

- A算法
- 爬山算法
- 分支限界法
- 动态规划法
- A*算法
- h函数与A*的关系
- A*算法实例

> 设目标节点从s搜素到t, 中间经过n
>
> 定义几个评价指标：
>
> k(s,n): 最佳路径耗散值
>
> c(ni,nk): 路径耗散值等于该路径上所有相邻节点间耗散值的总和。
>
> 1. g*(n) = k(s,n): 从初始节点s到节点n的最小耗散值路径的实际耗散值。
> 2. h*(n)=min k(n.ti): 从节点n到目标节点集ti中所有节点最小耗散值路径的实际耗散值中的最小值。
> 3. f\*(n) = g\*(n) + h*(n): 从初始节点s约束通过节点n的最小耗散值路径的耗散值。
> 4. 评价函数：f(n)=g(n)+h(n) 其中 f,g,h为f\*,g\*,h\*的估计值
>
> h(n)为启发函数，g(n) >= g*(n)

> 只考虑h(n), 爬山算法；只考虑g(n),分支限界法；
>
> 只考虑g(n),动态规划法
>
> > 解析，动态规划法仅保留queue中公共节点路径中耗散值最小的路径，余者删除；所以动态规划相比分支限界去掉了公共路径中的冗余部分，提高效率；如果问题空间是树结构，效率相同
> >
> > ？这样看，是BFS的用途；而算法课是DFS的拓扑路径



> - A*算法(最佳图搜索算法)
>
> > 如果算法A有h(n)<h*(n),则为A\*算法.
> >
> > > h*(n): 是n到t的最短的。实际预估的还要短，为什么？凸优化？
> > >
> > > h*(n)未说明如何计算，实际上如何计算的？
> > >
> > > h(n)=0, BFS. h(n)越大越好，越接近h*(n)越好，意味着剩下的分支数的减小。
> >
> > 几个结论：
> >
> > > A*不结束， 必有f(n)>f\*(s)
> > >
> > > A*结束前，必有f(n)<f\*(n)
> > >
> > > 对于有限图或无限图，如果存在路径，A*一定成功
> > >
> > > A*选中的任何节点f(n)<=f\*(s)
> >
> > ? A*失败的唯一原因是OPEN表为空， 不成立
>
> h(n)最好满足三角单调性限制，即c(ni,nj)>=h(ni)-h(nj)
>
> g(n)设计：与深度有关，或者路径长度
>
> h(n)设计：当前位置到目标位置的各种距离。

- 与或图

> 这个也易于理解，与的话就说明这两步都需要走才行。但有个好奇的问题就是那为什么不直接合并呢

与节点直接看作是连接节点，那么子节点分解的与节点的个数和为该节点的耗散值。

AO*算法

一般来说首先这里有一个h(n)函数，采用的就是启发式算法；对每个子节点找h(n)最小的，然后走h(n)最小的那条通路；如果走不通，则进行回溯。因为直接会回溯，所以没有g(n)就很正常

> 扩展：博弈搜索
>
> - 极大极小搜索
>
> 博弈搜索属于对抗的这种，即有对抗双方；双方可以进行对抗选择。然后A为先手，所以就想思考如何才能让A获胜。
>
> 全局有一个评价函数，评价值越高对A越有利。
>
> 因为是下棋所以考虑的就是对抗式搜索。
>
> A想让自己胜利会选择max策略，B想阻止A获胜会选择min策略。
>
> 极大极小搜索的策略就是先根据宽度优先生成规定深度的全部博弈树，并计算叶子节点的棋局值。然后，从底向上倒推非端节点的棋局值。最终寻找出一条路径
>
> $\alpha$-$\beta$搜索，在极大极小值算法的基础上增加了剪枝功能，并采用深度优先的策略进行搜索。？向上搜索还是向下搜索
>
> 很有效，代码不是那么难写，但需要花费一定功夫。
>
> 从某种程度上来说还是与子节点的排列顺序有关，即需要先搜索哪个节点

### 机器学习概述

设计一个学习系统，学习定义：对于某类任务T和性能度量P，如果一个计算机程序在T上以P衡量的性能随着经验E而自我完善，那么我们称这个计算机程序从经验中学习。

对于一个学习问题，必须明确：

- 任务的种类T
- 衡量标准P
- 经验的来源E，数据库

设计一个学习系统

（以西洋跳棋为例）

选择训练经验、选择目标函数、选择目标函数的表示、选择函数逼近算法（学习算法）、最终设计。

第一个关键属性，训练经验能否为系统的决策提供直接或间接的反馈。

- 系统可从直接的训练样例，即各种棋盘状态和对应的正确走子中学习。
- 系统可能仅有间接的信息，即很多过去对弈序列和最终结局。（间接学习经验）

第二个重要属性，训练样例的分布能多好第表示实例分布，最终系统的性能是通过后者来衡量



例子：西洋跳棋学习问题

> 这里展示的只是粗略的模型，其中也是包含技巧的。比如中间通过几个模型组合，然后怎么来做得到最优结果