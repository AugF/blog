---
title: '论文思考: Gated Graph Sequence Neural Networks, ICLR 2016'
copyright: true
top: 0
reward: false
mathjax: true
date: 2019-10-17 18:42:18
tags:
categories:
---

综述进行论述的点:
实际上就是从是否可以得到数学上精确的解出发。
1. 无限步
2. 有限步

是否有数据？
监督学习、非监督学习、无监督学习。


学习过程就是对一组数据进行评价，评价往往是预测值与真实值之间的关系。
其次，关于是否学习，其实就是看

-----

GNNs 2009
1. y是什么意思？

2. f为什么要放缩，f对边来说实际上就是简单的相加

3. gnns 使用Almeida-Pineda算法实现的，特点在于，首先通过传播过程使得整个图收敛，然后在收敛解上计算相应的梯度。
> 这里的收敛是保证了什么意思?

4. gg-nn把收敛的更新次数固定了T,并不能保证图的最终状态会达到不动点。由于更新次数T变成了固定值，因此GG-NN可以直接使用BPTT算法来进行梯度的计算

https://zhuanlan.zhihu.com/p/38051458  其中包含GNN的历史。细想下，semi-gnn其实也没有保证收敛性，只是第一篇由想到这个。  那么实际上CNN有保证收敛性吗？？
> 这里的实际的例子所说的是某个点的坐标(0,1), 经过图转移到了目的点(0,1)去，所以从某种意义上来说这里也没有错

5. 为什么提出GGS-NN? 其实理解上来看就是信念传播的想法
> 观看每一步，信息在图中到底传到哪里去了